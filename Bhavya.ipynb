{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek-paghdal/Content_Generation/blob/main/Bhavya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UmroclTq9zq"
      },
      "outputs": [],
      "source": [
        "# tf.config.set_visible_devices(tf.config.experimental.list_physical_devices('GPU')[0], 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQT-GQdnUFa6",
        "outputId": "187fa5c7-bf39-493a-ba2a-0c7a523d0520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "D21mvRsi7ifK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xIeDzCbb7Yju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/data.csv')"
      ],
      "metadata": {
        "id": "kzlOWrmVr0ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "ziMzL_X7r7HY",
        "outputId": "24c0032b-8411-4f84-e715-bdf06817d1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    _id  \\\n",
              "0  {'$oid': '600837a2b5425d67582e0d8a'}   \n",
              "1  {'$oid': '600837a3b5425d67582e0d8e'}   \n",
              "2  {'$oid': '600837a4b5425d67582e0d91'}   \n",
              "3  {'$oid': '600837a4b5425d67582e0d92'}   \n",
              "4  {'$oid': '600837a5b5425d67582e0d97'}   \n",
              "\n",
              "                                               title        datePublished  \\\n",
              "0  EU lawmakers to push audio-visual sector on ge...  2020-11-30 05:46:35   \n",
              "1  Construction startup Scaled Robotics raises a ...  2020-02-03 07:13:18   \n",
              "2  Roblox buys digital avatar startup Loom.ai â€“ T...  2020-12-14 11:10:15   \n",
              "3  ClickUp hits $1 billion valuation in $100M Ser...  2020-12-15 16:30:14   \n",
              "4  Spotify launches video podcasts worldwide, sta...  2020-07-21 07:13:39   \n",
              "\n",
              "                                         description  \\\n",
              "0  European Union lawmakers are considering wheth...   \n",
              "1  Industrial robots are expensive. But, then, so...   \n",
              "2  Roblox announced today that itâ€™s buying a digi...   \n",
              "3  Just six month after raising its first bit of ...   \n",
              "4  Spotify today announced the global launch of v...   \n",
              "\n",
              "                                             article  \\\n",
              "0  European Union lawmakers are considering wheth...   \n",
              "1  Industrial robots are expensive. But, then, so...   \n",
              "2  Roblox announced today that itâ€™s buying a digi...   \n",
              "3  Just six month after raising its first bit of ...   \n",
              "4  Spotify today announced the global launch of v...   \n",
              "\n",
              "                                            keywords  \n",
              "0  audio-visual, eu, geoblocking, Netflix, stream...  \n",
              "1  Battlefield, construction, Norwegian Construct...  \n",
              "2  Avatar, Bitmoji, bitstrips, computing, films, ...  \n",
              "3  Android, ClickUp, Craft Ventures, Georgian Par...  \n",
              "4           Spotify, streaming music, Video, YouTube  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a308481-0d9c-42bf-b1ec-11dd4ff78f14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>title</th>\n",
              "      <th>datePublished</th>\n",
              "      <th>description</th>\n",
              "      <th>article</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'$oid': '600837a2b5425d67582e0d8a'}</td>\n",
              "      <td>EU lawmakers to push audio-visual sector on ge...</td>\n",
              "      <td>2020-11-30 05:46:35</td>\n",
              "      <td>European Union lawmakers are considering wheth...</td>\n",
              "      <td>European Union lawmakers are considering wheth...</td>\n",
              "      <td>audio-visual, eu, geoblocking, Netflix, stream...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'$oid': '600837a3b5425d67582e0d8e'}</td>\n",
              "      <td>Construction startup Scaled Robotics raises a ...</td>\n",
              "      <td>2020-02-03 07:13:18</td>\n",
              "      <td>Industrial robots are expensive. But, then, so...</td>\n",
              "      <td>Industrial robots are expensive. But, then, so...</td>\n",
              "      <td>Battlefield, construction, Norwegian Construct...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'$oid': '600837a4b5425d67582e0d91'}</td>\n",
              "      <td>Roblox buys digital avatar startup Loom.ai â€“ T...</td>\n",
              "      <td>2020-12-14 11:10:15</td>\n",
              "      <td>Roblox announced today that itâ€™s buying a digi...</td>\n",
              "      <td>Roblox announced today that itâ€™s buying a digi...</td>\n",
              "      <td>Avatar, Bitmoji, bitstrips, computing, films, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'$oid': '600837a4b5425d67582e0d92'}</td>\n",
              "      <td>ClickUp hits $1 billion valuation in $100M Ser...</td>\n",
              "      <td>2020-12-15 16:30:14</td>\n",
              "      <td>Just six month after raising its first bit of ...</td>\n",
              "      <td>Just six month after raising its first bit of ...</td>\n",
              "      <td>Android, ClickUp, Craft Ventures, Georgian Par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'$oid': '600837a5b5425d67582e0d97'}</td>\n",
              "      <td>Spotify launches video podcasts worldwide, sta...</td>\n",
              "      <td>2020-07-21 07:13:39</td>\n",
              "      <td>Spotify today announced the global launch of v...</td>\n",
              "      <td>Spotify today announced the global launch of v...</td>\n",
              "      <td>Spotify, streaming music, Video, YouTube</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a308481-0d9c-42bf-b1ec-11dd4ff78f14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a308481-0d9c-42bf-b1ec-11dd4ff78f14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a308481-0d9c-42bf-b1ec-11dd4ff78f14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "1JQvsT44r_L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df[:3000]"
      ],
      "metadata": {
        "id": "-BGCUh5qsGUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv('data1.csv',index=False)"
      ],
      "metadata": {
        "id": "FUq2eKfXsMV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('data1.csv')"
      ],
      "metadata": {
        "id": "1wXKrlHUv8YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOBjvWgvwMHf",
        "outputId": "7825354c-4e35-4bc8-95e9-7eab33e33862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the dataset into train and evaluate**"
      ],
      "metadata": {
        "id": "9QyfG0fuvk2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, eval_data = train_test_split(data, test_size=0.2)"
      ],
      "metadata": {
        "id": "9eLn5dNLvrID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM6EwJs3wrL-",
        "outputId": "348b812e-ae81-4ce6-f936-8b6280208507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv('train_data.csv')\n",
        "eval_data.to_csv('eval_data.csv')\n"
      ],
      "metadata": {
        "id": "zPvJgszewvfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# this is for the train data\n",
        "\n",
        "# Open the CSV file and read the contents\n",
        "with open('/content/train_data.csv', 'r', encoding='utf-8') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    data = [row['article'] for row in reader]\n",
        "\n",
        "# Write the contents to a text file\n",
        "with open('/content/train_dataset.txt', 'w', encoding='utf-8') as txtfile:\n",
        "    txtfile.write('\\n'.join(data))\n"
      ],
      "metadata": {
        "id": "zWhtJPb6rQeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv\n",
        "\n",
        "# this is for the evaluate data\n",
        "\n",
        "# Open the CSV file and read the contents\n",
        "with open('/content/eval_data.csv', 'r', encoding='utf-8') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "    data = [row['article'] for row in reader]\n",
        "\n",
        "# Write the contents to a text file\n",
        "with open('/content/eval_dataset.txt', 'w', encoding='utf-8') as txtfile:\n",
        "    txtfile.write('\\n'.join(data))\n"
      ],
      "metadata": {
        "id": "fTOqWtRMxB6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKe_TIrZtQ7U",
        "outputId": "3499fda0-02e3-4fbf-cee2-3379f6698041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "D2rcW8IEtEh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained GPT-2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n"
      ],
      "metadata": {
        "id": "72GRRK53thcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare your dataset by creating a TextDataset object\n",
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='/content/train_dataset.txt',\n",
        "    block_size=128\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teLEUf84tmnS",
        "outputId": "29f1c4a4-e4b7-48d5-8231-4f32349d982a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare your dataset by creating a TextDataset object\n",
        "eval_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='/content/eval_dataset.txt',\n",
        "    block_size=128\n",
        ")\n"
      ],
      "metadata": {
        "id": "6XwMGM9axeRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pytorch-lightning[callbacks]"
      ],
      "metadata": {
        "id": "3USyqXlI9ix_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pytorch-lightning==1.2.7"
      ],
      "metadata": {
        "id": "FD4LjOwQ-Z4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade pytorch-lightning\n"
      ],
      "metadata": {
        "id": "2izCjJu1-8Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip uninstall pytorch-lightning\n"
      ],
      "metadata": {
        "id": "7lNMRGxH_2Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip freeze | grep pytorch-lightning\n"
      ],
      "metadata": {
        "id": "OBnQWp5T_3Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-lightning\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLSlI2rj_4zr",
        "outputId": "62a65ae1-4b33-4f81-8e52-e25a2d03b69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.9/dist-packages (2.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2023.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (0.8.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.10.7)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up the model checkpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='./checkpoints',\n",
        "    filename='checkpoint-{epoch:02d}',\n",
        "    save_top_k=2,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_last=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=data_collator,\n",
        "    eval_dataset=eval_dataset,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ncs3B3vN8g-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModelCheckpoint(ModelCheckpoint):\n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        super().on_train_start(trainer, pl_module)\n",
        "        # Your custom code here\n",
        "\n",
        "checkpoint_callback = CustomModelCheckpoint(\n",
        "    dirpath='./checkpoints',\n",
        "    filename='checkpoint-{epoch:02d}',\n",
        "    save_top_k=2,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_last=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=data_collator,\n",
        "    eval_dataset=eval_dataset,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "fRw2tZt_Mdvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# Set up the trainer with the appropriate training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
      ],
      "metadata": {
        "id": "zaBQDJbaB5ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModelCheckpoint(ModelCheckpoint):\n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        super().on_train_start(trainer, pl_module)\n",
        "        # Your custom code here\n",
        "\n",
        "\n",
        "checkpoint_callback = CustomModelCheckpoint(\n",
        "    dirpath='./checkpoints',\n",
        "    filename='checkpoint-{epoch:02d}',\n",
        "    save_top_k=2,\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    save_last=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=data_collator,\n",
        "    eval_dataset=eval_dataset,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "i5rC9T0cBs70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set up the trainer with the appropriate training arguments\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir='./results',\n",
        "#     evaluation_strategy='epoch',\n",
        "#     learning_rate=5e-5,\n",
        "#     per_device_train_batch_size=16,\n",
        "#     num_train_epochs=5,\n",
        "#     save_total_limit=2,\n",
        "# )\n",
        "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     data_collator=data_collator,\n",
        "#     eval_dataset=eval_dataset\n",
        "# )\n",
        "\n"
      ],
      "metadata": {
        "id": "fD9QozNhttZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model on your dataset\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "dDQ6Mbrgt1UP",
        "outputId": "94b533c0-674f-4222-9b4f-7b4a6e0b3b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4615' max='4615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4615/4615 46:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.592800</td>\n",
              "      <td>3.346953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.289700</td>\n",
              "      <td>3.309886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.157100</td>\n",
              "      <td>3.297071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.089000</td>\n",
              "      <td>3.296507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.043300</td>\n",
              "      <td>3.298493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4615, training_loss=3.218702177004334, metrics={'train_runtime': 2783.1486, 'train_samples_per_second': 26.52, 'train_steps_per_second': 1.658, 'total_flos': 4821491220480000.0, 'train_loss': 3.218702177004334, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "prIthD5_W1Gm",
        "outputId": "83355f0d-f2d7-4e2c-c444-83e6b4fbc253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='464' max='464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [464/464 00:39]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 3.298492670059204,\n",
              " 'eval_runtime': 39.8979,\n",
              " 'eval_samples_per_second': 92.937,\n",
              " 'eval_steps_per_second': 11.63,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer"
      ],
      "metadata": {
        "id": "j2m1KtL2W9Us",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081572f9-0d44-4d31-9dc9-680eee88d765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.trainer.Trainer at 0x7f49064843d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJmPE27_DT5u",
        "outputId": "fb3432ba-6134-4ee2-ad5d-c70a8c397878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "AEj0iM-_DWjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.to('cuda')a# Convert the model to CPU\n",
        "\n",
        "model = model.to(torch.device('cpu'))\n"
      ],
      "metadata": {
        "id": "b57VIFZN_T4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate text using the fine-tuned model\n",
        "prompt = 'which is the best phone that i can buy ?'\n",
        "generated_text = model.generate(\n",
        "    input_ids=tokenizer.encode(prompt, return_tensors='pt'),\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=1.0,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5dUnEdWt6nP",
        "outputId": "31ec0106-5c6e-4211-ddb5-a53bb311cc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "which is the best phone that i can buy?) for just $99. And then, with the exception of the base model, only $34 when it comes to hardware. The iPhone 5 is coming in two models, one with $799 in cash and one with $999 in cash, but with both starting at $1,599 in cash and $999 in cash.  The iPhone SE has $999 and $999. The iPhone 12 is coming in two versions with the base model and the entry-level models with the entry-level model with the entry-level model. If youâ€™re new to the line of iPhones and want to upgrade in price, this is your option. If youâ€™ve made it that far in your life and have a budget, this isnâ€™t the phone for you.  Buy your iPhone SE  and the iPhone SE   are the best and the best phones for you in the long run. The  iPhone  is not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.save_model('Second_Model_GPT2-Epoch_3_1000')"
      ],
      "metadata": {
        "id": "-GZrLfH4X2G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile(\"Model_2_GPT-2_Epoch_3_1000.zip\", \"r\")\n",
        "# zip_ref.extractall()\n",
        "# zip_ref.close()"
      ],
      "metadata": {
        "id": "QJUIMeuH_ugz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# joblib.dump(model, 'SecondModel_Epoch_3_1000_2.joblib')"
      ],
      "metadata": {
        "id": "3wewl0cLLYYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "joblib.dump(model, 'Model_Epoch_5_3000.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PinWs-VDqLC",
        "outputId": "0cef35ad-ce79-455c-afa1-2dd5cd296b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Model_Epoch_5_3000.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(tokenizer, 'tokenizer_5_3000.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrJO_8NmGWM3",
        "outputId": "aa792995-ecc7-439e-ea93-103c933799b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokenizer_5_3000.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQlOrgdUGG_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_joblib=joblib.load('SecondModel_Epoch_3_1000_2.joblib')"
      ],
      "metadata": {
        "id": "JNdlc7YtLx4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffswWlNC7V9f",
        "outputId": "f59d9079-2761-44aa-c9de-90ce6dabd206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_joblib"
      ],
      "metadata": {
        "id": "48rFugCaL6Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib as jb"
      ],
      "metadata": {
        "id": "a2YFZW6lMISB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jb.dump(model,'model_jb.pkl')"
      ],
      "metadata": {
        "id": "OXGm8JGwMlQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = jb.load('model_jb.pkl')"
      ],
      "metadata": {
        "id": "o0Y5jn9qMskS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate text using the fine-tuned model\n",
        "prompt = 'which is the best phone that i can buy ?'\n",
        "generated_text = loaded_model.generate(\n",
        "    input_ids=tokenizer.encode(prompt, return_tensors='pt').to('cuda'),\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=1.0,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(generated_text[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "RT6AQ776M9eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#new method"
      ],
      "metadata": {
        "id": "vTNn_KC60n6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib as jb"
      ],
      "metadata": {
        "id": "cWnFRwah0m6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKN4MpRI1Dgz",
        "outputId": "cf1917d5-e42c-42d1-aa6b-444ee069f514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers as tf\n"
      ],
      "metadata": {
        "id": "tK6Zn-N71IKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model=jb.load('/content/drive/MyDrive/Model_Epoch_5_3000.joblib')"
      ],
      "metadata": {
        "id": "m2pRR5DR075q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_tokenizer=jb.load('/content/drive/MyDrive/tokenizer_5_3000.joblib')"
      ],
      "metadata": {
        "id": "TUjU3QNM1w6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp36yBKv1CHA",
        "outputId": "7e91dbbe-bf71-400d-dc6b-209894df84cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKLIufva14j8",
        "outputId": "17149686-1560-4d9d-a3f0-40afde437cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate text using the fine-tuned model\n",
        "prompt = 'what is the use of machine learning'\n",
        "generated_text = loaded_model.generate(\n",
        "    input_ids=loaded_tokenizer.encode(prompt, return_tensors='pt'),\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=1.0,\n",
        "    # num_beams=5,\n",
        "    # early_stopping=True\n",
        ")\n",
        "\n",
        "print(loaded_tokenizer.decode(generated_text[0],\n",
        "                       skip_special_tokens=True\n",
        "                       ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhJXGKsE1ZvQ",
        "outputId": "5e04950c-7324-487b-d958-6673e400aba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the use of machine learning here? Youâ€™re talking about an AI program that can do a very deep search of a personâ€™s body, so much like Google. A user, like a doctor, might want to look at a personâ€™s body, or their whole body of their brain. And you see this sort of machine learning that could change and maybe even change where a person is located. How do you find that? Itâ€™s kind of like the machine learning of the Internet, which it has a lot of power in that it provides better information than people can use it. It could be a little bit more of a human voice or an electronic medical record. Or it could be in a cell phone, in a cell phone booth. And so on. Now, itâ€™s not a matter of having a data scientist or a person-scientist [at all], but rather, itâ€™s like, in this case, you get\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generated_text(input):\n",
        "  input_ids=loaded_tokenizer.encode(input,return_tensors='tf')\n",
        "  beam_output=loaded_model.generate(input_ids,\n",
        "                                    max_length=200,\n",
        "                                    num_beams=5,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    early_stopping=True)\n",
        "  ouput=loaded_tokenizer.decode(beam_output[0],\n",
        "                                skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "  \n",
        "  # return '.'.join(output.split('.')[:-1]) + \".\"\n",
        "  return output"
      ],
      "metadata": {
        "id": "ZlFmjEhR1nXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generated_text(input):\n",
        "  input_ids = loaded_tokenizer.encode(input, return_tensors='pt')\n",
        "  beam_output = loaded_model.generate(input_ids,\n",
        "                                      max_length=200,\n",
        "                                      num_beams=5,\n",
        "                                      no_repeat_ngram_size=2,\n",
        "                                      early_stopping=True)\n",
        "  output = loaded_tokenizer.decode(beam_output[0].tolist(),  # Convert to list\n",
        "                                   skip_special_tokens=True,\n",
        "                                   clean_up_tokenization_spaces=True)\n",
        "  return '.'.join(output.split('.')[:-1]) + \".\"\n"
      ],
      "metadata": {
        "id": "f5-N8qoR3h3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text('what is deep learning ?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "sDDI7zg82xG5",
        "outputId": "163a68f3-f8e7-4aa2-a5c2-e07971eac2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is deep learning? Itâ€™s a new kind of machine learning that can be applied to a lot of different kinds of data sets,â€ he said. â€œIt can tell the difference between a human being and a robot. It can also tell a story about a person or a machine. And it can do that in a way that is very human-like. So we think that Deep Learning is going to be a big part of the future of artificial intelligence, because it will be able to tell stories that are not just human, but also machine, and that will have a huge impact on the way people think about data and how they interact with it. We believe that this is the next frontier of AI, so we are excited to work with them to bring it to the forefront of this new era of human interaction and AI in the real world.\\nGoogle today  announced  that it has raised a $2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "2kvJHfD8t7zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load pre-trained word embeddings\n",
        "word_vectors =api.load('word2vec-google-news-300')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxvcqUfeuAgj",
        "outputId": "ad93802b-0ee6-4256-b66d-73ad46fd51e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.9% 1660.5/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdZ15cMxyWgq",
        "outputId": "dfe1c060-90d4-4325-e50c-846b1ee03d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ldMHp5PXybnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check(input):\n",
        "  input_ids = loaded_tokenizer.encode(input, return_tensors='pt')\n",
        "    \n",
        "    # Create attention mask\n",
        "  attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
        "    \n",
        "    # Generate text with attention mask and pad token ID\n",
        "  beam_output = loaded_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=200,\n",
        "        num_beams=5,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=loaded_tokenizer.pad_token_id,\n",
        "        eos_token_id=loaded_tokenizer.eos_token_id,\n",
        "        bos_token_id=loaded_tokenizer.bos_token_id,\n",
        "        \n",
        "    )\n",
        "    \n",
        "  output = loaded_tokenizer.decode(beam_output[0].tolist(),\n",
        "                                    skip_special_tokens=True,\n",
        "                                    clean_up_tokenization_spaces=True)\n",
        "    \n",
        "  return '.'.join(output.split('.')[:-1]) + \".\"\n"
      ],
      "metadata": {
        "id": "1ayb9oYL0UMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def new_generated_text(input):\n",
        "\n",
        "  string1='''Algorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,Wireless,WordPress,XML,XSS,YAML,Zend,Zip,ZoomArtificial Intelligence, Machine Learning, Data Science, Big Data, Cloud Computing, Cybersecurity, Internet of Things (IoT), Blockchain, Robotics, Virtual Reality (VR), Augmented Reality (AR), Natural Language Processing (NLP), Quantum Computing, 5G, Edge Computing, DevOps, Agile, Software Engineering, Computer Vision, Deep Learning, Neural Networks, Chatbots, Digital Transformation, Smart Cities, Smart Homes, Industry 4.0, Autonomous Vehicles, Drones, Wearable Technology, Biometric Authentication, Human-Computer Interaction (HCI), User Experience (UX), User Interface (UI), Product Management, Project Management, Agile Development, Scrum, Lean Startup, Growth Hacking, Data Analytics, Business Intelligence (BI), Customer Relationship Management (CRM), Enterprise Resource Planning (ERP), Supply Chain Management, e-Commerce, Digital Marketing, Search Engine Optimization (SEO), Social Media Marketing, Content Marketing, Email Marketing, Affiliate Marketing, Influencer Marketing, Mobile Marketing, Marketing Automation, Customer Acquisition, Customer Retention, Conversion Rate Optimization (CRO), A/B Testing, User Testing, User Research, Design Thinking, User-Centered Design (UCD), Graphic Design, Web Design, Mobile Design, Game Design, Product Design, Interaction Design, Information Architecture, Front-end Development, Back-end Development, Full-stack Development, JavaScript, Python, Java, Ruby, PHP, C++, C#, Swift, Kotlin, TypeScript, HTML, CSS, React, Angular, Vue.js, Node.js, Express.js, Django, Flask, Spring, Ruby on Rails, Laravel, WordPress, Magento, Shopify, WooCommerce, Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform, Firebase, Heroku, DigitalOcean, GitHub, GitLab, Bitbucket, Jenkins, Docker, Kubernetes, Ansible, Terraform, Elasticsearch, Logstash, Kibana, Grafana, Prometheus, Nagios, Splunk, Zabbix, New Relic, Sumo Logic, Apache Kafka, Apache Spark, Hadoop, MongoDB, MySQL, PostgreSQL, Oracle, Microsoft SQL Server, Redis, Cassandra, Couchbase, Neo4j, Elasticsearch, Solr, Lucene, Nginx, Apache HTTP Server, IIS, Apache Tomcat, Redis, Ansible Tower, Ansible Engine, Ansible Workbench, Ansible Galaxy, Ansible Core, Puppet, Chef, Salt, Vagrant, Consul, Nomad, Packer, OpenStack, Kubernetes-native, Serverless, Docker Swarm, Amazon ECS, Google Kubernetes Engine, Azure Container Service, Microsoft Azure Container Instances, Istio, Knative, OpenShift, Mesosphere, DC/OS, Fargate, Lambda, Azure Functions, Google Cloud Functions, OpenFaaS, Kubeless, AWS Lambda, Serverless Framework, AWS AppSync, GraphQL, Hasura, Prisma, Apollo, Nuxt.js, Gatsby, Next.js, Storybook, Jest, Cypress, Puppeteer, Selenium, Playwright, React Native, Ionic, Flutter, SwiftUI, Kotlin Multiplatform, Mobile App Development, MAlgorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,WirelesAlgorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,Wireless,WordPress,XML,XSS,YAML,Zend,Zip,Zooms,WordPress,XML,XSS,YAML,Zend,Zip,Zoomobile App Design, Mobile App Marketing, Mobile App Monetization, Mobile App Analytics, Mobile App User Acquisition, Mobile App User Retention, Mobile App User Engagement, Mobile App Push Notifications, Mobile App Personalization, Mobile App A/B Testing, Mobile App User Experience (UX), Mobile App User Interface (UI), Mobile App Accessibility, Mobile App Performance Optimization, Mobile App Security, Mobile App Privacy, Mobile App Data Analytics, Mobile App Business Intelligence, Mobile App CRM, Mobile App Customer Support, Mobile App Localization, Mobile App Internationalization, Mobile App Store Optimization (ASO), Mobile App Promotion, Mobile App Influencer,Apple, Samsung, Google Pixel, OnePlus, Xiaomi, Huawei, Oppo, Vivo, Realme, Sony Xperia, LG, Motorola, Nokia, HTC, BlackBerry, Asus Zenfone, Lenovo, ZTE, Meizu, Honor, Micromax, Karbonn, Lava, Intex, Gionee, Coolpad, Infinix, Tecno, Itel, Swipe, LYF, Jio, Reliance, Vivo, Panasonic, Philips, Sharp, Toshiba, Acer, Dell, HP, Lenovo ThinkPad, Microsoft Surface, Razer Phone, Redmi, Poco, Micromax Canvas, Yu, Asus ROG, Essential Phone, Alcatel, CAT, Black Shark, Elephone, Nokia Lumia, Mobiistar, Google Nexus, Google Pixel, LeEco, LeTV, Meizu, Motorola Moto, Nextbit Robin, Nvidia Shield, Obi Worldphone, OnePlus One, Oppo R, Samsung Galaxy, Sony Xperia, Ulefone'''\n",
        "  string1=string1.replace(',','')\n",
        "  tokens1 = word_tokenize(string1.lower())\n",
        "  tokens2 = word_tokenize(input.lower())\n",
        "\n",
        "# Convert tokens to vectors\n",
        "  vector1 = np.mean([word_vectors[token] for token in tokens1 if token in word_vectors], axis=0)\n",
        "  vector2 = np.mean([word_vectors[token] for token in tokens2 if token in word_vectors], axis=0)\n",
        "\n",
        "  \n",
        "# Calculate cosine similarity between the two vectors\n",
        "  similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "  print(f'the similarity score is {similarity}')\n",
        "  answer='As an AI langauge model, I have been trained to generate output that is only related to Technology domain. Therefore, I would not be able to answer your question.'\n",
        "  \n",
        "  if input in string1 or input in string1.lower():\n",
        "    return check(input)\n",
        "  elif similarity<=0.35:\n",
        "    return answer\n",
        "  else:\n",
        "    return check(input)\n",
        "    \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "8X9Klhle5e6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_generated_text('what is artificial intelligence ?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "Fg7wdHZPwas-",
        "outputId": "21cd62e4-df51-4480-f67a-9d376d43dc20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the similarity score is 0.36844587326049805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is artificial intelligence? Itâ€™s not a new concept, but it has been around for a long time. AI is the next big thing, and it is going to be a big part of the future of our lives,â€ he said. â€œAI will be used in a lot of different ways in different industries and industries. It will help people better understand what they need to do to survive and thrive in this new world. And it will make it easier for people to make decisions that are better for them and for their families and their communities. So we are excited to see what AI can do for us in the coming years. We are very excited about the possibilities of AI and how it can help us make better decisions for our families, our communities and our society. I want to thank all of you who have supported us over the past few years and have helped shape our future. Thank you so much for your support and support of us during this time of uncertainty.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  string1='''Artificial Intelligence, Machine Learning, Data Science, Big Data, Cloud Computing, Cybersecurity, Internet of Things (IoT), Blockchain, Robotics, Virtual Reality (VR), Augmented Reality (AR), Natural Language Processing (NLP), Quantum Computing, 5G, Edge Computing, DevOps, Agile, Software Engineering, Computer Vision, Deep Learning, Neural Networks, Chatbots, Digital Transformation, Smart Cities, Smart Homes, Industry 4.0, Autonomous Vehicles, Drones, Wearable Technology, Biometric Authentication, Human-Computer Interaction (HCI), User Experience (UX), User Interface (UI), Product Management, Project Management, Agile Development, Scrum, Lean Startup, Growth Hacking, Data Analytics, Business Intelligence (BI), Customer Relationship Management (CRM), Enterprise Resource Planning (ERP), Supply Chain Management, e-Commerce, Digital Marketing, Search Engine Optimization (SEO), Social Media Marketing, Content Marketing, Email Marketing, Affiliate Marketing, Influencer Marketing, Mobile Marketing, Marketing Automation, Customer Acquisition, Customer Retention, Conversion Rate Optimization (CRO), A/B Testing, User Testing, User Research, Design Thinking, User-Centered Design (UCD), Graphic Design, Web Design, Mobile Design, Game Design, Product Design, Interaction Design, Information Architecture, Front-end Development, Back-end Development, Full-stack Development, JavaScript, Python, Java, Ruby, PHP, C++, C#, Swift, Kotlin, TypeScript, HTML, CSS, React, Angular, Vue.js, Node.js, Express.js, Django, Flask, Spring, Ruby on Rails, Laravel, WordPress, Magento, Shopify, WooCommerce, Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform, Firebase, Heroku, DigitalOcean, GitHub, GitLab, Bitbucket, Jenkins, Docker, Kubernetes, Ansible, Terraform, Elasticsearch, Logstash, Kibana, Grafana, Prometheus, Nagios, Splunk, Zabbix, New Relic, Sumo Logic, Apache Kafka, Apache Spark, Hadoop, MongoDB, MySQL, PostgreSQL, Oracle, Microsoft SQL Server, Redis, Cassandra, Couchbase, Neo4j, Elasticsearch, Solr, Lucene, Nginx, Apache HTTP Server, IIS, Apache Tomcat, Redis, Ansible Tower, Ansible Engine, Ansible Workbench, Ansible Galaxy, Ansible Core, Puppet, Chef, Salt, Vagrant, Consul, Nomad, Packer, OpenStack, Kubernetes-native, Serverless, Docker Swarm, Amazon ECS, Google Kubernetes Engine, Azure Container Service, Microsoft Azure Container Instances, Istio, Knative, OpenShift, Mesosphere, DC/OS, Fargate, Lambda, Azure Functions, Google Cloud Functions, OpenFaaS, Kubeless, AWS Lambda, Serverless Framework, AWS AppSync, GraphQL, Hasura, Prisma, Apollo, Nuxt.js, Gatsby, Next.js, Storybook, Jest, Cypress, Puppeteer, Selenium, Playwright, React Native, Ionic, Flutter, SwiftUI, Kotlin Multiplatform, Mobile App Development, MAlgorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,WirelesAlgorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,Wireless,WordPress,XML,XSS,YAML,Zend,Zip,Zooms,WordPress,XML,XSS,YAML,Zend,Zip,Zoomobile App Design, Mobile App Marketing, Mobile App Monetization, Mobile App Analytics, Mobile App User Acquisition, Mobile App User Retention, Mobile App User Engagement, Mobile App Push Notifications, Mobile App Personalization, Mobile App A/B Testing, Mobile App User Experience (UX), Mobile App User Interface (UI), Mobile App Accessibility, Mobile App Performance Optimization, Mobile App Security, Mobile App Privacy, Mobile App Data Analytics, Mobile App Business Intelligence, Mobile App CRM, Mobile App Customer Support, Mobile App Localization, Mobile App Internationalization, Mobile App Store Optimization (ASO), Mobile App Promotion, Mobile App Influencer,Apple, Samsung, Google Pixel, OnePlus, Xiaomi, Huawei, Oppo, Vivo, Realme, Sony Xperia, LG, Motorola, Nokia, HTC, BlackBerry, Asus Zenfone, Lenovo, ZTE, Meizu, Honor, Micromax, Karbonn, Lava, Intex, Gionee, Coolpad, Infinix, Tecno, Itel, Swipe, LYF, Jio, Reliance, Vivo, Panasonic, Philips, Sharp, Toshiba, Acer, Dell, HP, Lenovo ThinkPad, Microsoft Surface, Razer Phone, Redmi, Poco, Micromax Canvas, Yu, Asus ROG, Essential Phone, Alcatel, CAT, Black Shark, Elephone, Nokia Lumia, Mobiistar, Google Nexus, Google Pixel, LeEco, LeTV, Meizu, Motorola Moto, Nextbit Robin, Nvidia Shield, Obi Worldphone, OnePlus One, Oppo R, Samsung Galaxy, Sony Xperia, Ulefone, Vodafone Smart, Xiaomi Mi, ZTE Nubia.   '''\n"
      ],
      "metadata": {
        "id": "XlJEDY4Ly41s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_Tech_art(s2):\n",
        "  # Tokenize the strings\n",
        "  tokens1 = word_tokenize(string1.lower())\n",
        "  tokens2 = word_tokenize(s2)\n",
        "\n",
        "# Convert tokens to vectors\n",
        "  vector1 = np.mean([word_vectors[token] for token in tokens1 if token in word_vectors], axis=0)\n",
        "  vector2 = np.mean([word_vectors[token] for token in tokens2 if token in word_vectors], axis=0)\n",
        "\n",
        "# Calculate cosine similarity between the two vectors\n",
        "  similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "  print(similarity)\n",
        "  if similarity >= 0.55:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n"
      ],
      "metadata": {
        "id": "SvUAdwcFyt4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_Tech_art('give me some knowledge about finance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-n4uFR8y_SR",
        "outputId": "bd00bb29-3500-415a-984b-c21a76f092c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30888936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def is_Tech_art(s2):\n",
        "#   # Tokenize the strings\n",
        "#   string1='''Artificial Intelligence, Machine Learning, Data Science, Big Data, Cloud Computing, Cybersecurity, Internet of Things (IoT), Blockchain, Robotics, Virtual Reality (VR), Augmented Reality (AR), Natural Language Processing (NLP), Quantum Computing, 5G, Edge Computing, DevOps, Agile, Software Engineering, Computer Vision, Deep Learning, Neural Networks, Chatbots, Digital Transformation, Smart Cities, Smart Homes, Industry 4.0, Autonomous Vehicles, Drones, Wearable Technology, Biometric Authentication, Human-Computer Interaction (HCI), User Experience (UX), User Interface (UI), Product Management, Project Management, Agile Development, Scrum, Lean Startup, Growth Hacking, Data Analytics, Business Intelligence (BI), Customer Relationship Management (CRM), Enterprise Resource Planning (ERP), Supply Chain Management, e-Commerce, Digital Marketing, Search Engine Optimization (SEO), Social Media Marketing, Content Marketing, Email Marketing, Affiliate Marketing, Influencer Marketing, Mobile Marketing, Marketing Automation, Customer Acquisition, Customer Retention, Conversion Rate Optimization (CRO), A/B Testing, User Testing, User Research, Design Thinking, User-Centered Design (UCD), Graphic Design, Web Design, Mobile Design, Game Design, Product Design, Interaction Design, Information Architecture, Front-end Development, Back-end Development, Full-stack Development, JavaScript, Python, Java, Ruby, PHP, C++, C#, Swift, Kotlin, TypeScript, HTML, CSS, React, Angular, Vue.js, Node.js, Express.js, Django, Flask, Spring, Ruby on Rails, Laravel, WordPress, Magento, Shopify, WooCommerce, Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform, Firebase, Heroku, DigitalOcean, GitHub, GitLab, Bitbucket, Jenkins, Docker, Kubernetes, Ansible, Terraform, Elasticsearch, Logstash, Kibana, Grafana, Prometheus, Nagios, Splunk, Zabbix, New Relic, Sumo Logic, Apache Kafka, Apache Spark, Hadoop, MongoDB, MySQL, PostgreSQL, Oracle, Microsoft SQL Server, Redis, Cassandra, Couchbase, Neo4j, Elasticsearch, Solr, Lucene, Nginx, Apache HTTP Server, IIS, Apache Tomcat, Redis, Ansible Tower, Ansible Engine, Ansible Workbench, Ansible Galaxy, Ansible Core, Puppet, Chef, Salt, Vagrant, Consul, Nomad, Packer, OpenStack, Kubernetes-native, Serverless, Docker Swarm, Amazon ECS, Google Kubernetes Engine, Azure Container Service, Microsoft Azure Container Instances, Istio, Knative, OpenShift, Mesosphere, DC/OS, Fargate, Lambda, Azure Functions, Google Cloud Functions, OpenFaaS, Kubeless, AWS Lambda, Serverless Framework, AWS AppSync, GraphQL, Hasura, Prisma, Apollo, Nuxt.js, Gatsby, Next.js, Storybook, Jest, Cypress, Puppeteer, Selenium, Playwright, React Native, Ionic, Flutter, SwiftUI, Kotlin Multiplatform, Mobile App Development, MAlgorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,WirelesAlgorithm,Analytics,Android,Antivirus,API,App,Application,Artificial intelligence,Augmented reality,Automation,Backend,Bandwidth,Binary,Bit,Bitcoin,Blockchain,Blog,Bluetooth,Bot,Browser,Cache,Camera,CDN,Chatbot,Circuit,Cloud,CMS,Code,Compiler,Computer,Computing,Cryptography,CSS,Cybersecurity,Data,Database,Debugging,Deep learning,Desktop,DevOps,Device,Digital,Display,Disruptive technology,Domain,Download,E-commerce,Edge computing,Email,Encryption,Enterprise,Event,File,Firmware,Firewall,Framework,Freeware,Frontend,Function,Gateway,Geolocation,GIF,Google,GPU,Graphic design,Grid computing,Growth hacking,Guest post,Gzip,Hardware,Headphones,HTML,HTTP,HTTPS,Hyperlink,Hypertext,IAAS,IDE,Inbound marketing,Index,Information,Infrastructure,Innovation,Input,Interface,Internet,Internet of things,IOS,IP,IP address,IPv4,IPv6,Java,JavaScript,JSON,Keyword,LAMP,LAN,Language,Laptop,Laravel,Layer,Linux,Load balancer,Localhost,Log,Machine learning,Malware,Marketing,Metadata,Microservices,Middleware,Migration,ML,Mobile,Model,Multimedia,MySQL,Native app,Network,Neural network,Nginx,Node.js,Object-oriented programming,Online,Operating system,Optimization,OS,Outsourcing,Overlay,Packet,Password,PC,Performance,Perl,PHP,Platform,Plugin,PM,Podcast,Port,Power bank,Privacy,Processor,Programming,Protocol,Python,Query,Queue,RAM,Ransomware,React,Reboot,Responsive design,REST,Robotics,Ruby,SAAS,Scalability,Scanner,Schema,Script,SDN,Search engine optimization,Security,Server,Service,Shell,SMTP,Software,Source code,Speech recognition,SQL,SSH,SSL,Startup,Storage,Streaming,Subnet,Supercomputer,SVG,System,Tablet,TCP/IP,Technology,Tensorflow,Terminal,Testing,Text editor,Theme,Third-party,Timeline,Traffic,Transmission,Typeface,UI,UNIX,Update,Upload,URL,User,UX,Vector,Version control,Video,Virtual machine,Virtual reality,Virtualization,VPN,Vulnerability,Web,Web design,Web development,Web hosting,Web server,WebGL,Website,Widget,Wireless,WordPress,XML,XSS,YAML,Zend,Zip,Zooms,WordPress,XML,XSS,YAML,Zend,Zip,Zoomobile App Design, Mobile App Marketing, Mobile App Monetization, Mobile App Analytics, Mobile App User Acquisition, Mobile App User Retention, Mobile App User Engagement, Mobile App Push Notifications, Mobile App Personalization, Mobile App A/B Testing, Mobile App User Experience (UX), Mobile App User Interface (UI), Mobile App Accessibility, Mobile App Performance Optimization, Mobile App Security, Mobile App Privacy, Mobile App Data Analytics, Mobile App Business Intelligence, Mobile App CRM, Mobile App Customer Support, Mobile App Localization, Mobile App Internationalization, Mobile App Store Optimization (ASO), Mobile App Promotion, Mobile App Influencer,Apple, Samsung, Google Pixel, OnePlus, Xiaomi, Huawei, Oppo, Vivo, Realme, Sony Xperia, LG, Motorola, Nokia, HTC, BlackBerry, Asus Zenfone, Lenovo, ZTE, Meizu, Honor, Micromax, Karbonn, Lava, Intex, Gionee, Coolpad, Infinix, Tecno, Itel, Swipe, LYF, Jio, Reliance, Vivo, Panasonic, Philips, Sharp, Toshiba, Acer, Dell, HP, Lenovo ThinkPad, Microsoft Surface, Razer Phone, Redmi, Poco, Micromax Canvas, Yu, Asus ROG, Essential Phone, Alcatel, CAT, Black Shark, Elephone, Nokia Lumia, Mobiistar, Google Nexus, Google Pixel, LeEco, LeTV, Meizu, Motorola Moto, Nextbit Robin, Nvidia Shield, Obi Worldphone, OnePlus One, Oppo R, Samsung Galaxy, Sony Xperia, Ulefone, Vodafone Smart, Xiaomi Mi, ZTE Nubia.   '''\n",
        "#   string1=string1.replace(',','')\n",
        "#   tokens1 = word_tokenize(string1.lower())\n",
        "#   tokens2 = word_tokenize(s2.lower())\n",
        "\n",
        "# # Convert tokens to vectors\n",
        "#   vector1 = np.mean([word_vectors[token] for token in tokens1 if token in word_vectors], axis=0)\n",
        "#   vector2 = np.mean([word_vectors[token] for token in tokens2 if token in word_vectors], axis=0)\n",
        "\n",
        "# # Calculate cosine similarity between the two vectors\n",
        "#   similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "#   # if similarity >= 0.55:\n",
        "#   #   return 1\n",
        "#   # else:\n",
        "#   #   return 0\n",
        "#   if similarity<=0.30:\n",
        "#     print('As an AI langauge model, I have been trained to generate output that is only related to Technology domain. Therefore, I would not be able to answer your question.')\n",
        "#   else if s2 in string1 or s2 in string1.lower():\n",
        "#     return \n",
        "#     # return '.'.join(output.split('.')[:-1]) + \".\"\n",
        "#   else :\n",
        "#     return '.'.join(output.split('.')[:-1]) + \".\"\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "EQrv4JPrr7xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "XI0Fvl_I6F2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_generated_text('what is deep learning ?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "03WiZ6f05-19",
        "outputId": "5fa74b12-fefd-4d44-8e25-a119d038bb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is deep learning? Itâ€™s a new kind of machine learning that can be applied to a lot of different kinds of data sets,â€ he said. â€œIt can tell the difference between a human being and a robot. It can also tell a story about a person or a machine. And it can do that in a way that is very human-like. So we think that Deep Learning is going to be a big part of the future of artificial intelligence, because it will be able to tell stories that are not just human, but also machine, and that will have a huge impact on the way people think about data and how they interact with it. We believe that this is the next frontier of AI, so we are excited to work with them to bring it to the forefront of this new era of human interaction and AI in the real world.\\nGoogle today  announced  that it has raised a $2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function():\n",
        "    a = 'idf si fds'\n",
        "    if a != 0:\n",
        "        return a\n",
        "        \n",
        "my_function()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bR9YqWN_vnJn",
        "outputId": "a7ec59d2-1414-4d37-cdd6-f99b1036d02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'idf si fds'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "d2sCHyZUSsQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "usONcSMcUDmv",
        "outputId": "9776c448-37a5-4211-8346-4c816e731bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d8238d9949b4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# !pip install -U spacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python -m spacy download en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    165\u001b[0m   \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "HZYMTpLFTIjO",
        "outputId": "f9767c3d-e979-46ea-d5f0-07821be4ba1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8229327e7d86>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_lg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s1='India'\n",
        "s2=''"
      ],
      "metadata": {
        "id": "J31NLAGrTOxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}